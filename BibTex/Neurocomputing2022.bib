@article{ZHANG2022270,
title = {Revisiting instance search: A new benchmark using cycle self-training},
journal = {Neurocomputing},
volume = {501},
pages = {270-284},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.06.027},
url = {https://www.sciencedirect.com/science/article/pii/S0925231222007445},
author = {Yuqi Zhang and Chong Liu and Weihua Chen and Xianzhe Xu and Fan Wang and Hao Li and Shiyu Hu and Xin Zhao},
keywords = {Instance search, Self training, Instance detection, Instance retrieval},
abstract = {Instance search aims at retrieving a particular object instance from a set of scene images. Although studied in previous competitions like TRECVID, there have been limited literature or datasets on this topic. In this paper, to overcome the generalization issue when arbitrary categories are involved in search and to benefit from the large amount of unlabeled data, we propose a cycle self-training framework which trains the instance search pipeline with automatic supervision. Given the two-stage pipeline with a localization and ranking module, the cycle self-training includes a ranker-guided localizer, and a localizer-guided ranker, each carefully designed to handle noisy labels that come with self-supervision. Furthermore, we build and release large-scale groundtruth annotations for instances to facilitate the algorithm evaluation and analysis in this research topic, especially for small objects in complex background. The datasets are publicly available at https://github.com/instance-search/instance-search. Extensive experiments show the effectiveness of the proposed cycle self-training framework and the superior performance compared with other state-of-the-art methods.}
}